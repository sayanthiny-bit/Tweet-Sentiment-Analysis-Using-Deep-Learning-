{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "chFxLC6rxIuW"
      },
      "outputs": [],
      "source": [
        "#Import all the libraries needed\n",
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM,Bidirectional,Dense,Dropout # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preview dataset"
      ],
      "metadata": {
        "id": "GDa_MsDyx_Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Declaring the english stop words"
      ],
      "metadata": {
        "id": "Uh5243vMyKhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "nzux8uRZxIuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a71bde0-87a9-4575-82cc-bbea5248f4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "english_stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing and Encoding labels"
      ],
      "metadata": {
        "id": "lA4BqsNlySGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dSRVxC5JxIuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2204ff46-832d-43b8-e058-d5f0243e46b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "          tweet_id  label                                              tweet\n",
            "0     6.430000e+17      0  user_mention all i can tell you is i have had ...\n",
            "1     6.440000e+17      0  my doctor told me stop he gave me sum pop i mi...\n",
            "2     8.150000e+17      1  i take tylenol and i wake up in the middle of ...\n",
            "3     6.820000e+17      0  i got xans in an advil bottle i dont take them...\n",
            "4     6.440000e+17      1  mom says i need to stop eating so much bc ive ...\n",
            "...            ...    ...                                                ...\n",
            "9986  6.480000e+17      1                          that vicodin messed me up\n",
            "9987  5.710000e+17      0                  user_mention get some tylenol lol\n",
            "9988  6.470000e+17      0                          like a walking tamiflu ad\n",
            "9989  6.990000e+17      0                         klay and steph on steroids\n",
            "9990  8.230000e+17      0                    horrible pops another xanax url\n",
            "\n",
            "[9991 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_train = pathlib.Path('/content/drive/My Drive/Assignment_02/phm_train.csv')\n",
        "data_test = pathlib.Path('/content/drive/My Drive/Assignment_02/phm_test.csv')\n",
        "data_train = pd.read_csv(data_train)\n",
        "print(data_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test = pd.read_csv(data_test)\n",
        "print(data_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g80eS6BXIF0_",
        "outputId": "60e8a7ea-4823-41f8-f646-92fa087d5bb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          tweet_id  label                                              tweet\n",
            "0     6.430000e+17      0  user_mention all i can tell you is i have had ...\n",
            "1     6.440000e+17      0  my doctor told me stop he gave me sum pop i mi...\n",
            "2     8.150000e+17      1  i take tylenol and i wake up in the middle of ...\n",
            "3     6.820000e+17      0  i got xans in an advil bottle i dont take them...\n",
            "4     6.440000e+17      1  mom says i need to stop eating so much bc ive ...\n",
            "...            ...    ...                                                ...\n",
            "9986  6.480000e+17      1                          that vicodin messed me up\n",
            "9987  5.710000e+17      0                  user_mention get some tylenol lol\n",
            "9988  6.470000e+17      0                          like a walking tamiflu ad\n",
            "9989  6.990000e+17      0                         klay and steph on steroids\n",
            "9990  8.230000e+17      0                    horrible pops another xanax url\n",
            "\n",
            "[9991 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AkYrwkMJjzkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uL16UfD6xIua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02f2508-e22b-4d3c-85a2-218c3975257c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweets:\n",
            "0       [user, mention, tell, relapses, cure, hear, do...\n",
            "1       [doctor, told, stop, gave, sum, pop, mix, w, a...\n",
            "2       [take, tylenol, wake, middle, night, put, ice,...\n",
            "3       [got, xans, advil, bottle, dont, take, shits, ...\n",
            "4       [mom, says, need, stop, eating, much, bc, ive,...\n",
            "                              ...                        \n",
            "9986                                    [vicodin, messed]\n",
            "9987                   [user, mention, get, tylenol, lol]\n",
            "9988                         [like, walking, tamiflu, ad]\n",
            "9989                              [klay, steph, steroids]\n",
            "9990                [horrible, pops, another, xanax, url]\n",
            "Name: tweet, Length: 9991, dtype: object \n",
            "\n",
            "0    [try, run, away, iv, needle, doctor, drug, w, ...\n",
            "1    [knew, took, ambien, sleep, early, im, ready, ...\n",
            "2    [mean, get, celexa, reason, behind, lot, weigh...\n",
            "3    [call, dumb, dumb, one, time, dont, care, many...\n",
            "4    [want, go, grocery, store, cant, pay, anyone, ...\n",
            "Name: tweet, dtype: object \n",
            "\n",
            "Labels:\n",
            "0       0\n",
            "1       0\n",
            "2       1\n",
            "3       0\n",
            "4       1\n",
            "       ..\n",
            "9986    1\n",
            "9987    0\n",
            "9988    0\n",
            "9989    0\n",
            "9990    0\n",
            "Name: label, Length: 9991, dtype: int64\n",
            "0    0\n",
            "1    1\n",
            "2    1\n",
            "3    0\n",
            "4    0\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def preprocess(tweets):\n",
        "    tweets = tweets.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    tweets = tweets.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    tweets = tweets.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
        "    tweets = tweets.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "\n",
        "    return tweets\n",
        "\n",
        "def load_dataset():\n",
        "  # tarin data\n",
        "    x_train = data_train['tweet']       # Tweets/Input\n",
        "    y_train = data_train['label']    # labels/Output\n",
        "\n",
        "  # test data\n",
        "    x_test = data_test['tweet']       # Tweets/Input\n",
        "    y_test = data_test['label']\n",
        "\n",
        "    x_train = preprocess(x_train)\n",
        "    x_test = preprocess(x_test)\n",
        "\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_dataset()\n",
        "\n",
        "print('Tweets:')\n",
        "print(x_train, '\\n')\n",
        "print(x_test.head(), '\\n')\n",
        "print('Labels:')\n",
        "print(y_train)\n",
        "print(y_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Cf37dMjxIub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3155ce23-2e84-4d1e-a0b9-defcb3f28c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set\n",
            "4571    [anndd, relaaxx, call, clonazepam, dead, kenne...\n",
            "8572       [somebody, pls, get, dj, khaled, tylenol, url]\n",
            "914     [user, mention, user, mention, user, mention, ...\n",
            "6767    [spent, six, hours, er, tonight, zofran, morph...\n",
            "4938    [days, predinsone, covered, hydrocortisone, an...\n",
            "                              ...                        \n",
            "4582    [window, boxes, must, steroids, excited, explo...\n",
            "9933                                [anyone, deck, xanax]\n",
            "4512    [user, mention, tylenol, new, best, friend, de...\n",
            "5297    [ok, honestly, morphine, entire, vmas, dont, r...\n",
            "8245    [user, mention, panadol, please, bakit, kasi, ...\n",
            "Name: tweet, Length: 7992, dtype: object \n",
            "\n",
            "4571    0\n",
            "8572    0\n",
            "914     1\n",
            "6767    1\n",
            "4938    1\n",
            "       ..\n",
            "4582    0\n",
            "9933    0\n",
            "4512    0\n",
            "5297    1\n",
            "8245    0\n",
            "Name: label, Length: 7992, dtype: int64 \n",
            "\n",
            "Test Set\n",
            "8640                        [target, hours, sleep, xanax]\n",
            "4823    [user, mention, user, mention, candidate, prop...\n",
            "3671    [like, take, tylenol, shit, didnt, work, anyth...\n",
            "764     [user, mention, makes, sense, demands, delayed...\n",
            "9258           [user, mention, tea, tylenol, youll, good]\n",
            "                              ...                        \n",
            "1627    [whats, wrong, young, guys, gym, almost, found...\n",
            "4224    [user, mention, yes, good, boy, gave, lollypop...\n",
            "6401         [yes, yes, high, im, looking, dexilant, url]\n",
            "736     [tylenol, dont, working, messed, cuz, real, ba...\n",
            "249     [er, called, surgeon, sure, said, theyre, givi...\n",
            "Name: tweet, Length: 1999, dtype: object \n",
            "\n",
            "8640    0\n",
            "4823    0\n",
            "3671    1\n",
            "764     0\n",
            "9258    0\n",
            "       ..\n",
            "1627    0\n",
            "4224    0\n",
            "6401    1\n",
            "736     1\n",
            "249     1\n",
            "Name: label, Length: 1999, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#train to test split\n",
        "#x_train, x_test, y_train, y_test = train_test_split(x_data_train, y_data_train, test_size = 0.2)\n",
        "\n",
        "#print('Train Set')\n",
        "#print(x_train, '\\n')\n",
        "#print(y_train, '\\n')\n",
        "#print('Test Set')\n",
        "##print(x_test, '\\n')\n",
        "#print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for getting the maximum review length, by calculating the mean of all the reviews length (using numpy.mean)"
      ],
      "metadata": {
        "id": "yaz82yjyykT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "B-5QgyYgxIuc"
      },
      "outputs": [],
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize and Pad/Truncate Reviews\n",
        "#post, pad or truncate the words in the back of a sentence\n",
        "#pre, pad or truncate the words in front of a sentence"
      ],
      "metadata": {
        "id": "ASGim_ImyrZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "j3dXUq6QxIuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096dbded-4c32-4998-cbbd-9cd8fd2d23d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[    2     1   200 ...   944  3624  1952]\n",
            " [  115   122   147 ...   193    40   322]\n",
            " [    6     3   330 ...   626  1710    29]\n",
            " ...\n",
            " [    7   529  1739 ...     0     0     0]\n",
            " [12658 12659     8 ...     0     0     0]\n",
            " [  645  1436   174 ...     0     0     0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[  98  606  109 ...  193    4  318]\n",
            " [ 585   11   56 ...   16  707   55]\n",
            " [ 327   12 1209 ...  778    5   88]\n",
            " ...\n",
            " [   2    1  126 ...    0    0    0]\n",
            " [   2    1    3 ...    0    0    0]\n",
            " [  59    8    9 ...    0    0    0]] \n",
            "\n",
            "Maximum review length:  10\n"
          ]
        }
      ],
      "source": [
        "# ENCODE tweets\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the LSTM model"
      ],
      "metadata": {
        "id": "EGmkzZzryxRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set hyperparameters\n",
        "lstm_model .compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "GaEkDqp0y3s8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM MODEL\n",
        "embedding_dim = 100\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(Embedding(total_words, embedding_dim, input_length = max_length))\n",
        "lstm_model.add(LSTM(64, return_sequences=True))\n",
        "lstm_model.add(LSTM(32))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model.build(input_shape=(None, max_length))\n",
        "\n",
        "print(lstm_model.summary())\n"
      ],
      "metadata": {
        "id": "SVfJMRR3sWOc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "9766e5b1-9805-41c5-9861-dbf6c0bae8fb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,266,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m42,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,266,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,320,689\u001b[0m (5.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,320,689</span> (5.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,320,689\u001b[0m (5.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,320,689</span> (5.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "HfXVls9hzBrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ncwxJzJ4xIud"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "gY6F99qYRorZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "e_DGv7xXxIud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098c61a3-25fa-4447-ad89-cd2e811081bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7107 - loss: 0.5968\n",
            "Epoch 1: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.7119 - loss: 0.5950\n",
            "Epoch 2/10\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8510 - loss: 0.3539\n",
            "Epoch 2: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8510 - loss: 0.3538\n",
            "Epoch 3/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9047 - loss: 0.2510\n",
            "Epoch 3: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.9046 - loss: 0.2511\n",
            "Epoch 4/10\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9291 - loss: 0.1921\n",
            "Epoch 4: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9290 - loss: 0.1924\n",
            "Epoch 5/10\n",
            "\u001b[1m77/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9353 - loss: 0.1705\n",
            "Epoch 5: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9354 - loss: 0.1705\n",
            "Epoch 6/10\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9547 - loss: 0.1318\n",
            "Epoch 6: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9546 - loss: 0.1321\n",
            "Epoch 7/10\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9675 - loss: 0.1002\n",
            "Epoch 7: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9673 - loss: 0.1005\n",
            "Epoch 8/10\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9616 - loss: 0.1107\n",
            "Epoch 8: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.9616 - loss: 0.1106\n",
            "Epoch 9/10\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9764 - loss: 0.0746\n",
            "Epoch 9: accuracy did not improve from 0.97428\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9763 - loss: 0.0748\n",
            "Epoch 10/10\n",
            "\u001b[1m78/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9815 - loss: 0.0631\n",
            "Epoch 10: accuracy improved from 0.97428 to 0.97988, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9815 - loss: 0.0631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78891d39d350>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "lstm_model.fit(x_train, y_train, batch_size = 128, epochs =10, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model testing"
      ],
      "metadata": {
        "id": "DqUvLFwhzGYk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "7cIDxgtxxIud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce01cf6-c26c-4ce6-d888-d3723bbbea3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Correct Prediction: 2595\n",
            "Wrong Prediction: 736\n",
            "Accuracy: 77.90453317322125\n"
          ]
        }
      ],
      "source": [
        "pred = lstm_model.predict(x=x_test)\n",
        "y_pred = (pred >= 0.5) * 1\n",
        "\n",
        "#y_pred = model.predict(x_test)\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvWhkDfXxIug"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}